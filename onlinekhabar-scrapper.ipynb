{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport re\nfrom multiprocessing import Pool\nimport pandas as pd\nimport os\nfrom itertools import chain\nimport concurrent.futures\nimport glob\nimport numpy as np\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.retry import Retry","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-03T02:51:00.990624Z","iopub.execute_input":"2022-06-03T02:51:00.990982Z","iopub.status.idle":"2022-06-03T02:51:01.351822Z","shell.execute_reply.started":"2022-06-03T02:51:00.990893Z","shell.execute_reply":"2022-06-03T02:51:01.350964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting link of a single page\ndef article_links(soupp):\n  \n  temp=[]\n\n  tempo = list(soupp.find_all('div',class_=['span-4','post-img-wrap']))\n\n  for i in tempo:\n    temp.append(i.find('a').get('href'))\n\n  return temp\n\n# Getting links of multiple pages\ndef loop_over_pages(date_link):\n    links = []\n    while True:\n\n        source = requests.get(str(date_link)).text\n        soup = BeautifulSoup(source, 'html.parser')\n        links.append(article_links(soup))\n        if soup.find('a',{'class':'next page-numbers'}) != None:\n            date_link = soup.find('a',{'class':'next page-numbers'}).get('href')\n#             print(\"hello next page\")\n        else:\n            break\n    return links\n","metadata":{"execution":{"iopub.status.busy":"2022-06-03T02:51:04.90419Z","iopub.execute_input":"2022-06-03T02:51:04.904524Z","iopub.status.idle":"2022-06-03T02:51:05.596071Z","shell.execute_reply.started":"2022-06-03T02:51:04.904474Z","shell.execute_reply":"2022-06-03T02:51:05.595278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting all links of month of April of 2022\nLinks  = loop_over_pages(\"https://www.english.onlinekhabar.com/2022/04\")","metadata":{"execution":{"iopub.status.busy":"2022-06-03T02:51:17.661589Z","iopub.execute_input":"2022-06-03T02:51:17.661892Z","iopub.status.idle":"2022-06-03T02:51:17.6758Z","shell.execute_reply.started":"2022-06-03T02:51:17.661862Z","shell.execute_reply":"2022-06-03T02:51:17.674845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_extract(link):\n    df= pd.DataFrame(columns = ['catagory','heading','text','date','link'])\n    session = requests.Session()\n    retry = Retry(connect=3, backoff_factor=0.5)\n    adapter = HTTPAdapter(max_retries=retry)\n    session.mount('http://', adapter)\n    session.mount('https://', adapter)\n    try:\n        source = session.get(link,allow_redirects=False)\n        soup = BeautifulSoup(source.content.decode(\"UTF-8\"), 'html.parser')\n    except:\n        return ['None']\n    \n    #News texts\n    text_extracted = ''\n    try:\n        text_extracted = ''\n        article = soup.find(\"div\", {\"class\":[\"post-content-wrap\"]}).findAll('p')\n        for element in article[1:]:\n            text_extracted += '\\n' + ''.join(element.findAll(text = True))\n    except:\n        text_extracted = \"None\"\n      \n    a=[text_extracted]\n    return a","metadata":{"execution":{"iopub.status.busy":"2022-06-03T02:54:14.472124Z","iopub.execute_input":"2022-06-03T02:54:14.472416Z","iopub.status.idle":"2022-06-03T02:54:14.486993Z","shell.execute_reply.started":"2022-06-03T02:54:14.472387Z","shell.execute_reply":"2022-06-03T02:54:14.486296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df= pd.DataFrame(columns = ['catagory','heading','text','date','link'])\nwith concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n    result=executor.map(data_extract,Links)    \nfor r in result:\n    final_df=final_df.append({'text':r[0],ignore_index=True) \nfinal_df.to_csv(r'./onlinekhabar1.csv',index=False,header=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:38:00.326989Z","iopub.status.idle":"2022-02-08T17:38:00.327402Z","shell.execute_reply.started":"2022-02-08T17:38:00.327206Z","shell.execute_reply":"2022-02-08T17:38:00.327224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}